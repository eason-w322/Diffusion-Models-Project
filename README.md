# Diffusion Models for Image Generation

This project explores **diffusion-based generative models** for image synthesis. Diffusion models generate high-quality images by learning to iteratively denoise samples from a simple noise distribution, reversing a gradual forward noising process. The project emphasizes both the theoretical foundations of diffusion models and their practical implementation for image generation.

---

## Overview

Diffusion models operate by defining a **forward noising process** that gradually corrupts data with Gaussian noise, and a **learned reverse process** that reconstructs the data by removing noise step by step. Unlike adversarial training, diffusion models are trained with a stable objective and produce samples through an explicit iterative procedure.

---

## Methodology

### Forward Process
The forward process progressively adds Gaussian noise to an input image over a fixed number of timesteps, transforming it into nearly pure noise. The noise schedule controls how quickly information is destroyed and plays a critical role in training stability and sample quality.

### Reverse Process
The reverse process is modeled by a neural network trained to predict the noise added at each timestep. Conditioning the model on the timestep allows it to learn how to denoise images at varying noise levels and recover clean samples from noisy inputs.

---

## Model Architecture

The denoising network is implemented as a **time-conditioned neural model**, commonly using a UNet-style architecture. The model receives a noisy image and a timestep embedding as input and outputs a noise estimate, which is used to compute a cleaner image in the reverse diffusion step.

---

## Training Objective

The model is trained using a mean squared error (MSE) loss between the true noise injected during the forward process and the noise predicted by the network. This objective provides a simple and effective approximation to the reverse diffusion process and enables stable training.

---

## Sampling and Generation

After training, images are generated by sampling Gaussian noise and iteratively applying the learned denoising model from the final timestep to the initial timestep. Intermediate denoising steps can be visualized to illustrate how meaningful structure gradually emerges from noise.

---

## Results

<p align="center">
  <img src="epoch10.png" width="600">
</p>

The generated samples demonstrate the modelâ€™s ability to progressively refine noisy inputs into coherent images, highlighting the effectiveness of diffusion-based generation.
